---
title: "Praca domowa 3"
author: "Joanna Gajewska"
date: "2 April 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r , echo =FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidyr)
library(ranger)
library(mlr)
```

#Wstęp

Dane, na których będę pracować pochodzą ze stroy : https://www.kaggle.com/c/walmart-recruiting-trip-type-classification/data
i dotyczą  kategoryzowania rodzajów podróży zakupowych na podstawie przedmiotów zakupionych przez klientów. 
Cechy jakie zawierają dane, to:

TripType - kategoryczny identyfikator reprezentujący rodzaj zakupów dokonanych przez klienta. 

VisitNumber - identyfikator odpowiadający pojedynczej podróży jednego klienta

Weekday - dzień tygodnia podróży

Upc - numer UPC zakupionego produktu

ScanCount - numer zakupionego przedmiotu. Wartość ujemna oznacza zwrot produktu.

DepartmentDescription - opis  działu produktu

FinelineNumber - kategoria dla każdego produktu stworzonego przez Walmart


# Inżynieria cech

W pierwszej kolejności, pobiorę i oczyszcze dane z wartości NA. 
W kolejnym kroku, będę modyfikować zbiór danych, dodawać nowe cechy, oraz usówać potencjalnie mało znaczące cechy.

```{r pressure, echo =FALSE, message=FALSE, warning=FALSE}

data<-read.table("train.csv", sep=",", header = TRUE)


#Czyszczenie danych z wartości NA
row.has.na <- apply(data, 1, function(x){any(is.na(x))})
data_no_na<- data[!row.has.na,]


data_no_na %>% 
  group_by(VisitNumber) %>%
  summarise(TripType = head(TripType,1),
            count = n(),
            day = unique(Weekday)[1],
            number_of_product=sum(ScanCount),
            number_of_departments=n_distinct(DepartmentDescription)) ->gr_visit_number

data_new<-data_no_na

work_data<- dplyr::inner_join(data_new, gr_visit_number)


work_data$Weekend<-0
work_data$Weekend[work_data$Weekday == "Sunday"]<-1
work_data$Weekend[work_data$Weekday == "Saturday"]<-1

work_data$AlmostWeekend<-0
work_data$AlmostWeekend[work_data$Weekday == "Friday"]<-1
work_data$AlmostWeekend[work_data$Weekday == "Monday"]<-1

work_data$MiddleOfWeek<-0
work_data$MiddleOfWeek[work_data$Weekday == "Tuesday"]<-1
work_data$MiddleOfWeek[work_data$Weekday == "Wednesday"]<-1
work_data$MiddleOfWeek[work_data$Weekday == "Thursday"]<-1

work_data_2<-subset(work_data, select=c( "TripType", "VisitNumber", "ScanCount",
                                         "DepartmentDescription", "FinelineNumber",
                                         "Weekend",  "AlmostWeekend", "MiddleOfWeek",
                                         "number_of_product", "number_of_departments"  ))


number_of_rows<-nrow(work_data_2)
ready_data<-work_data_2
ready_data$DepartmentDescription<-fct_lump_min(work_data_2$DepartmentDescription, min=0.007*number_of_rows)


```


#Test ACC

Następnie, po uzyskaniu dwóch zbiorów danych -  pierwotny, jedynie z usuniętymi wartociami NA oraz zmodyfikowany przeze mnie zbiór danych, w którym pojawiły się nowe cechy, takie jak : 

Weekend - wartości binarne, dla zakupów zrobionych w niedziele, sobotę 

AlmostWeekend- wartości binarne, dla zakupów zrobionych w poniedzialek, piątek         

MiddleOfWeek  - wartości binarne, dla zakupów zrobionych we wtorek, środę i czwartek

number_of_product - ilość kupionych produktów podczas jednej wizyty w sklepie    

number_of_departments - ilość odwiedzonych działów podczas jednej wizyty w sklepie

Cechy, które zdecydowałam się usunąć z nowego zbioru danych to "Upc" i "Weekday". 

Następnie korzystająć z klasyfikatora RANGER-
(Szybka implementacja lasów losowych, szczególnie nadaje się do danych o dużych wymiarach)
treonawałam model, aby porównać wyniki testu ACC dla dwóch zbiorów.

```{r,  echo =FALSE, message=FALSE, warning=FALSE}
# początkowy zbiór danych

set.seed(123)
train_set_org <- sample_frac(data_no_na, 0.6)
test_set_org<- setdiff(data_no_na, train_set_org)


task_org <- makeClassifTask(data = train_set_org, target="TripType")
learner_org <- makeLearner("classif.ranger", predict.type = "prob", par.vals = list(num.trees=40))
train_org <- train(learner = learner_org,task = task_org)

pred_org <- predict(train_org,newdata=test_set_org)

CM_org <- table(pred_org$data$response, test_set_org$TripType)

ACC_org<-sum(diag(CM_org))/sum(CM_org)


#Zbiór danych po inżynierii cech

set.seed(123)

train_set <- sample_frac(ready_data, 0.6)
test_set<- setdiff(ready_data, train_set)

task <- makeClassifTask(data = train_set, target="TripType")
learner <- makeLearner("classif.ranger", predict.type = "prob", par.vals = list(num.trees=40))
train <- train(learner = learner,task = task)

pred <- predict(train,newdata=test_set)

CM <- table(pred$data$response, test_set$TripType)

ACC<-sum(diag(CM))/sum(CM)


ACC_all<-data.frame(ACC_orginal=ACC_org, ACC_clean=ACC)

ACC_all


```


Jak widać wynik testu ACC znacznie się poprawił dla zbioru zmodyfikowanego. 
