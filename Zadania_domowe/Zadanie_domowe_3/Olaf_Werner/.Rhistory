setwd("~/Desktop/2019L-WUM/Zadania_domowe/Zadanie_domowe_3/Olaf_Werner")
kable(head(mtcars), format = "markdown", padding = 0)
# more padding
kable(head(mtcars), format = "markdown", padding = 2)
setwd("~/Desktop/WUM_projekt1")
heloc_ok<-read.csv(file = "heloc_ok.csv")
train_index <- sample(1:nrow(heloc_ok), 0.8 * nrow(heloc_ok))
train <- heloc_ok[train_index,]
test <- heloc_ok[-train_index,]
# Task
task <- makeClassifTask(data = train, target = "RiskPerformance")
library(tidyverse)
library(dplyr)
library(FNN)
library(ranger)
library(mlr)
library(DALEX)
# Task
task <- makeClassifTask(data = train, target = "RiskPerformance")
test_task <- makeClassifTask(data = test, target = "RiskPerformance")
custom_predict_classif <- function(object, newdata) {pred <- predict(object, newdata=newdata)
response <- pred$data[,3]
return(response)}
# RF
rf_lrn <- makeLearner("classif.randomForest",
predict.type = "prob",
ntree=500)
model_rf <- train(rf_lrn, task)
explainer_rf <- explain(model_rf,
data = test,
y = as.numeric(test$RiskPerformance)-1,
predict_function = custom_predict_classif,
label="randomForest")
# GBM
gbm_lrn <- makeLearner("classif.gbm",
par.vals = list(),
predict.type = "prob")
model_gbm <- train(gbm_lrn, task)
explainer_gbm <- explain(model_gbm,
data = test,
y = as.numeric(test$RiskPerformance)-1,
predict_function = custom_predict_classif,
label="gbm")
# QDA
qda_lrn <- makeLearner("classif.qda",
predict.type = "prob")
model_qda <- train(qda_lrn, task)
explainer_qda <- explain(model_qda,
data = test,
y = as.numeric(test$RiskPerformance)-1,
predict_function = custom_predict_classif,
label="qda")
# RPART
rpart_lrn <- makeLearner("classif.rpart",
predict.type = "prob")
model_rpart <- train(rpart_lrn, task)
explainer_rpart <- explain(model_rpart,
data = test,
y = as.numeric(test$RiskPerformance)-1,
predict_function = custom_predict_classif,
label="rpart")
# SVM
svm_lrn <- makeLearner("classif.svm",
predict.type = "prob")
model_svm <- train(svm_lrn,
task)
explainer_svm <- explain(model_svm,
data = test,
y = as.numeric(test$RiskPerformance)-1,
predict_function = custom_predict_classif,
label = "svm")
# Model Performance
mp_rf <- model_performance(explainer_rf)
mp_gmb <- model_performance(explainer_gbm)
mp_qda <- model_performance(explainer_qda)
mp_rpart <- model_performance(explainer_rpart)
mp_svm <- model_performance(explainer_svm)
plot(mp_svm)
vi <- variable_importance(explainer = explainer_svm,
loss_function = loss_root_mean_square)
plot(vi)
plot(mp_rf, mp_gmb, mp_qda,mp_rpart,mp_svm, geom = "boxplot")
plot(vi)
?variable_importance
View(vi)
vi <- variable_importance(explainer = explainer_svm,
loss_function = loss_root_mean_square)
plot(vi)
?ROCPlot
View(test)
predict(model_svm,test$RiskPerformance)
?predict
?predict
predict(model_svm,test,test$RiskPerformance)
predict(model_svm,task,test$RiskPerformance)
?mlr::predictLearner()
predict(model_svm,newdata=test)
pred_svm<-predict(model_svm,newdata=test)
pred_svm<-predict(model_svm,newdata=test)
pred_rf<-predict(model_rf,newdata=test)
pred_rpart<-predict(model_rpart,newdata=test)
pred_gbm<-predict(model_gbm,newdata=test)
pred_qda<-predict(model_qda,newdata=test)
df = generateThreshVsPerfData(list(svm = pred_svm, rf = pred_rf,rpart=pred_rpart,gbm=pred_gbm,qda=pred_qda), measures = list(fpr, tpr))
plotROCCurves(df)
?include_graphics
# Libraries
knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(mlr)
library(ggplot2)
library(DALEX)
library(kableExtra)
# Wczytywanie datasetu
# readr::read_csv("final_dataset.csv", col_types = cols(
#   library = col_factor(),
#   model_name = col_factor(),
#   numberOfCategoricalFeatures = col_double(),
#   numberOfNumericalFeatures = col_double(),
#   meanUniqueNumericalValues = col_double(),
#   meanUniqueCategoricalValues = col_double(),
#   meanNumberMissing = col_double(),
#   number_of_instances = col_double(),
#   ACC = col_double()
# )) -> df
# Dataset preparation
# df <- df[!is.na(df$meanUniqueNumericalValues), ]
# df <- df[!is.na(df$meanUniqueCategoricalValues), ]
knitr::include_graphics("krzywa_git.png",dpi = 100)
knitr::include_graphics("krzywa_git.png",dpi = 1000)
library(knitr)
knitr::include_graphics("variables_Ida.png")
knitr::include_graphics("variables_ida.png")
knitr::include_graphics("variables_lda.png")
knitr::include_graphics("AUCasia.png")
mcls <- function(pred) {
cols <- paste0("prob.", pred$data$truth)
coli <- match(cols, colnames(pred$data))
N <- nrow(pred$data)
row <- 1:N
out <- as.numeric(pred$data[cbind(row, coli)])
out <- pmax(pmin(out, 1-1e-15), 1e-15)
return(-sum(log(out))/N)
}
setwd("~/Desktop/2019L-WUM/Zadania_domowe/Zadanie_domowe_3/Olaf_Werner")
train <- read_csv("train.csv")
#train<-sample_frac(train,0.02)
wizyty<-unique(train$VisitNumber)
wizyty<-sample(wizyty,size = floor(length(wizyty)/100),replace = FALSE)
train<-train[train$VisitNumber %in% wizyty,]
train<-filter(train,!is.na(FinelineNumber)) %>% select(-Upc)
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
train$TripType<-factor(train$TripType)
model<-"classif.gbm"
task = makeClassifTask(id = "task", data = train,"TripType" )
learner<-makeLearner(model)
cv <- makeResampleDesc("CV", iters = 5)
library(mlr)
model_gbm<-mlr::train(learner,task)
test<-read_csv("test.csv")
View(test)
test<-filter(test,!is.na(FinelineNumber)) %>% select(-Upc)
test[sapply(train, is.character)] <- lapply(test[sapply(test, is.character)],as.factor)
pred_gbm<-predict(model_gbm,test)
pred_gbm<-predict(model_gbm,newdata=test)
mcls(pred = )
mcls(pred = pred_gbm)
pred_gbm$threshold
pred_gbm$threshold<-0.5
mcls(pred = pred_gbm)
sample(2)
